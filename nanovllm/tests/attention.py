import torch

from transformers import AutoConfig, Glm4MoeConfig
from nanovllm.models.glm4_moe.attention import Glm4MoeAttention

def main():

    torch.manual_seed(42)
    torch.set_default_device("cuda")
    torch.set_default_dtype(torch.float16)

    # init_distributed_environment(world_size=1, rank=0)

    model = "/data/model/ZhipuAI/GLM-4.5-Air"
    config = AutoConfig.from_pretrained(model)
    config = Glm4MoeConfig(config)
    # print(f"{config=}")

    prefix = "model.layers.1.self_attn"
    attn = Glm4MoeAttention(config, prefix=prefix)

    attn.load_weights(model)

    import safetensors
    import os
    sample_path = "/data/ai_infra/debug/glm4-6-awq-tensors"
    tensor_path = os.path.join(sample_path, f"{prefix}_0.safetensors")
    loaded_tensor = safetensors.torch.load_file(tensor_path)
    hidden_states = loaded_tensor["hidden_states"]
    positions = loaded_tensor["positions"]
    output_reference = loaded_tensor["output"]

    # print(f"{hidden_states.shape=}, {positions.shape=}")
    output = attn(hidden_states, positions)
    # print(f"{output.shape=}")

    torch.testing.assert_close(output, output_reference, rtol=1e-3, atol=1e-3)


if __name__ == "__main__":
    main()

import torch
import os
import safetensors
from transformers import AutoConfig
# å‡è®¾ä½ çš„moe.pyåœ¨nanovllm.models.glm4_moeåŒ…ä¸­
from nanovllm.models.glm4_moe.moe import Glm4MoeMoE

def main():
    torch.manual_seed(42)
    torch.set_default_device("cuda")
    torch.set_default_dtype(torch.float16)

    model_path = "/data/model/ZhipuAI/GLM-4.5-Air"
    config = AutoConfig.from_pretrained(model)

    # --- æ¨¡æ¿æ”¹åŠ¨ 1: å®šä¹‰ prefix ---
    # MoEå±‚åœ¨GLM-4ä¸­é€šå¸¸åä¸º "mlp"
    # æˆ‘ä»¬æµ‹è¯•ç¬¬1å±‚ (layers.1)
    layer_idx = 1
    prefix = f"model.layers.{layer_idx}.mlp"
    
    print(f"Initializing MoE layer for prefix: {prefix}")
    # --- æ¨¡æ¿æ”¹åŠ¨ 2: ä½¿ç”¨ prefix åˆå§‹åŒ–æ¨¡å‹ ---
    moe = Glm4MoeMoE(config, prefix=prefix)

    # --- æ¨¡æ¿æ”¹åŠ¨ 3: è°ƒç”¨ load_weights ---
    print(f"Loading weights from {model_path} for prefix {prefix}")
    moe.load_weights(model_path, prefix)
    print("âœ… MoE weights loaded.")

    # --- æ¨¡æ¿æ”¹åŠ¨ 4: åŠ è½½é¢„è®¡ç®—çš„è¾“å…¥å’Œå‚è€ƒè¾“å‡º ---
    # å‡è®¾ä½ æœ‰ä¸€ä¸ªç›®å½•å­˜æ”¾äº†ç”¨äºè°ƒè¯•çš„tensors
    sample_path = "/data/ai_infra/debug/glm4-6-awq-tensors"
    
    # æ„é€ ä¸prefixåŒ¹é…çš„tensoræ–‡ä»¶å
    tensor_file = f"{prefix}_{layer_idx}.safetensors" # ä¾‹å¦‚: model.layers.1.mlp_1.safetensors
    tensor_path = os.path.join(sample_path, tensor_file)

    if not os.path.exists(tensor_path):
        print(f"âš ï¸ Reference tensor file not found at: {tensor_path}")
        print("Falling back to randomly generated input for shape check.")
        # å¦‚æœæ²¡æœ‰å‚è€ƒæ–‡ä»¶ï¼Œå°±åªæ£€æŸ¥å½¢çŠ¶
        # æ³¨æ„ï¼šHFçš„MLPè¾“å…¥æ˜¯ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ª
        hidden_states = torch.randn(8192, config.hidden_size, device="cuda", dtype=torch.float16)
        # MoEçš„forwardéœ€è¦3Dè¾“å…¥
        output = moe(hidden_states.view(1, 8192, config.hidden_size))
        print(f"Input shape: {hidden_states.view(1, 8192, config.hidden_size).shape}")
        print(f"Output shape: {output.shape}")
        assert output.shape == hidden_states.view(1, 8192, config.hidden_size).shape
        print("âœ… Shape check passed with random input.")
        return

    print(f"Loading reference tensors from: {tensor_path}")
    loaded_tensor = safetensors.torch.load_file(tensor_path)
    
    # åŠ è½½è¾“å…¥å’Œå‚è€ƒè¾“å‡º
    hidden_states = loaded_tensor["hidden_states"].to(device="cuda")
    output_reference = loaded_tensor["output"].to(device="cuda")
    
    print(f"Input shape: {hidden_states.shape}")
    print(f"Reference output shape: {output_reference.shape}")

    # --- æ¨¡æ¿æ”¹åŠ¨ 5: æ‰§è¡Œå‰å‘ä¼ æ’­å¹¶éªŒè¯ ---
    output = moe(hidden_states)
    print(f"Your MoE output shape: {output.shape}")

    # éªŒè¯ç»“æœ
    assert output.shape == output_reference.shape, "Output shape mismatch!"
    
    print("\nComparing outputs...")
    try:
        torch.testing.assert_close(output, output_reference, rtol=1e-3, atol=1e-3)
        print("ğŸ‰ Verification passed! Your MoE implementation matches the reference.")
    except AssertionError as e:
        print(f"âš ï¸ Verification failed: {e}")
        print("The output difference is larger than the tolerance.")

if __name__ == "__main__":
    main()
